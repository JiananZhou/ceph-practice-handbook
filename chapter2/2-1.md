### 2.1 向ceph集群添加OSD

#### 2.1.1 自动部署

**1 磁盘准备**

```
root@ceph0:~/my-cluster# ceph-deploy osd prepare ceph0:/dev/vdb1 ceph1:/dev/vdb1 ceph2:/dev/vdb1
```

**2 设置权限**

```
root@ceph0:~/my-cluster# chown ceph:ceph /dev/vdb1
root@ceph0:~/my-cluster# ssh ceph1 'chown ceph:ceph /dev/vdb1'
root@ceph0:~/my-cluster# ssh ceph2 'chown ceph:ceph /dev/vdb1'
```

**3 启动OSD**

```
root@ceph0:~/my-cluster# ceph-deploy osd activate ceph0:/dev/vdb1 ceph1:/dev/vdb1 ceph2:/dev/vdb1
```

运行ceph -s，可以看到3个osd节点已经加入。

```
root@ceph0:~/my-cluster# ceph -s
    cluster 4d7e1b04-2a4c-45aa-b6fe-a98241db0c2f
     health HEALTH_WARN
            too few PGs per OSD (12 < min 30)
     monmap e1: 3 mons at {ceph0=172.20.0.196:6789/0,ceph1=172.20.0.197:6789/0,ceph2=172.20.0.198:6789/0}
            election epoch 4, quorum 0,1,2 ceph0,ceph1,ceph2
     osdmap e80: 3 osds: 3 up, 3 in
            flags sortbitwise
      pgmap v181: 64 pgs, 1 pools, 0 bytes data, 0 objects
            525 MB used, 2792 GB / 2792 GB avail
                  64 active+clean
```

#### 2.1.2 手动部署

以手动部署 osd.0 为例，手动过程如下：

1、创建OSD目录，并把磁盘挂载到该目录

```
mkdir /var/lib/ceph/osd/ceph-0
mkfs -t xfs -d name=/dev/sda1 -f
mount -noatime /dev/sda1 /var/lib/ceph/osd/ceph-0/
```

2、初始化OSD数据目录

```
ceph-osd -i 0 --mkfs --mkkey
```

3、注册OSD的key权限

```
ceph auth add osd.0 osd 'allow *' mon 'allow profile osd' -i /var/lib/ceph/osd/ceph-0/keyring
```

4、添加OSD节点到 crush map中

```
ceph create osd		
ceph osd crush add osd.0 1.0 host=ceph01
```

5、启动OSD

```
start ceph-osd id=0
```

### 2.2 启动/停止/重启

**1 启动**

```
sudo start ceph-osd id={osd-num}
```

一旦你启动了 OSD ，其状态就由 down 变成 up。

**2 停止**

```
sudo stop ceph-osd id={osd-num}
```

停止 OSD 后，状态变为 down 。

**3 重启**

```
sudo restart ceph-osd id={osd-num}
```

### 2.3 暂停/开启OSD

1、暂停OSD，暂停后整个集群不再接收数据

```
ceph osd pause
```

2、开启后再次接收数据

```
ceph osd unpause
```

### 2.4 踢出/加入集群

把 OSD 踢出集群

删除 OSD 前，它通常是 up 且 in 的，要先把它踢出集群，以使 Ceph 启动重新均衡、把数据拷贝到其他 OSD 。

```
ceph osd out {osd-num}
```

同样的，把OSD加入集群

```
ceph osd in {osd-num}
```

### 2.5 删除OSD

此步骤依次把一个 OSD 移出集群 CRUSH 图、删除认证密钥、删除 OSD 图条目：

1、删除 CRUSH 图的对应 OSD 条目，它就不再接收数据了。

```
ceph osd crush remove {name}		// ex: name = osd.0
```

2、删除 OSD 认证密钥：

```
ceph auth del osd.{osd-num}
```

3、ceph-{osd-num} 路径里的 ceph 值是 $cluster-$id ，如果集群名字不是 ceph ，这里要更改。

删除 OSD 。

```
ceph osd rm {osd-num}
```

